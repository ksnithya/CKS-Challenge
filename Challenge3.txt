Challenge3:
Step1:
--------

Download 'kube-bench' from AquaSec and extract it under '/opt' filesystem. Use the appropriate steps from the kube-bench docs to complete this task.
Run 'kube-bench' with config directory set to '/opt/cfg' and '/opt/cfg/config.yaml' as the config file. Redirect the result to '/var/www/html/index.html' file.

1.1. First we can setup kube-bench

root@controlplane ~ ➜  cd /opt

root@controlplane /opt ➜  curl -L https://github.com/aquasecurity/kube-bench/releases/download/v0.6.2/kube-bench_0.6.2_linux_amd64.tar.gz -o kube-bench_0.6.2_linux_amd64.tar.gz
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 7821k  100 7821k    0     0  15.9M      0 --:--:-- --:--:-- --:--:-- 15.9M

root@controlplane /opt ➜  ls -l
total 7836
drwxr-xr-x 1 root root    4096 Jan  6 20:54 cni
drwx--x--x 4 root root    4096 Jan  6 20:55 containerd
-rw-r--r-- 1 root root 8009592 Mar 21 11:00 kube-bench_0.6.2_linux_amd64.tar.gz
root@controlplane /opt ✖ tar -xvzf kube-bench_0.6.2_linux_amd64.tar.gz
root@controlplane /opt ➜  ls -l
total 25264
drwxr-xr-x 10 root root       4096 Mar 21 11:01 cfg
drwxr-xr-x  1 root root       4096 Jan  6 20:54 cni
drwx--x--x  4 root root       4096 Jan  6 20:55 containerd
-rwxr-xr-x  1 etcd docker 17838153 May 26  2021 kube-bench
-rw-r--r--  1 root root    8009592 Mar 21 11:00 kube-bench_0.6.2_linux_amd64.tar.gz

1.2. Now we can collect the data.

root@controlplane /opt ➜  mkdir -p /var/www/html

root@controlplane /opt ➜  ./kube-bench run --config-dir=/opt/cfg --config=/opt/cfg/config.yaml > /var/www/html/index.html

Step2:
-------

Ensure that the --protect-kernel-defaults argument is set to true (node01)

2.1. Find the kubelet config file and add line "protectKernelDefaults: true" 

root@controlplane /opt ➜  kubectl get node
NAME           STATUS   ROLES                  AGE   VERSION
controlplane   Ready    control-plane,master   15m   v1.23.0
node01         Ready    <none>                 14m   v1.23.0

root@controlplane /opt ➜  ssh node01

root@node01 /etc/kubernetes ➜  ps -ef|grep -i kubelet
root        1529       1  0 10:23 ?        00:01:15 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.6
root       18028   16165  0 11:14 pts/0    00:00:00 grep -i kubelet

root@node01 /etc/kubernetes ➜  vi /var/lib/kubelet/config.yaml

root@node01 /etc/kubernetes ➜  cat /var/lib/kubelet/config.yaml
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    cacheTTL: 0s
    enabled: true
  x509:
    clientCAFile: /etc/kubernetes/pki/ca.crt
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 0s
    cacheUnauthorizedTTL: 0s
cgroupDriver: systemd
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
cpuManagerReconcilePeriod: 0s
evictionPressureTransitionPeriod: 0s
fileCheckFrequency: 0s
healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 0s
imageMinimumGCAge: 0s
kind: KubeletConfiguration
logging:
  flushFrequency: 0
  options:
    json:
      infoBufferSize: "0"
  verbosity: 0
memorySwap: {}
nodeStatusReportFrequency: 0s
nodeStatusUpdateFrequency: 0s
resolvConf: /run/systemd/resolve/resolv.conf
rotateCertificates: true
runtimeRequestTimeout: 0s
shutdownGracePeriod: 0s
shutdownGracePeriodCriticalPods: 0s
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 0s
syncFrequency: 0s
volumeStatsAggPeriod: 0s
protectKernelDefaults: true --  add this line

root@node01 /etc/kubernetes ➜  

root@node01 /etc/kubernetes ➜  systemctl restart kubelet

Step 3:
--------

Ensure that the --protect-kernel-defaults argument is set to true (controlplane)

3.1. First we can find the kubelet config file.
root@controlplane /opt ➜  ps -ef|grep -i kubelet
root        3097    2970  0 10:23 ?        00:02:54 kube-apiserver --advertise-address=192.17.165.6 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-account-signing-key-file=/etc/kubernetes/pki/sa.key --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
root        3741       1  0 10:23 ?        00:01:55 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.6
root       30194   12663  0 11:19 pts/0    00:00:00 grep --color=auto -i kubelet

root@controlplane /opt ➜  vi /var/lib/kubelet/config.yaml
protectKernelDefaults: true --  add this line at last then restart the service

root@controlplane /opt ➜  systemctl restart kubelet

root@controlplane /opt ➜  

Step 4:
---------
Ensure that the --profiling argument is set to false
Ensure PodSecurityPolicy admission controller is enabled
Ensure that the --insecure-port argument is set to 0
Ensure that the --audit-log-path argument is set to /var/log/apiserver/audit.log
Ensure that the --audit-log-maxage argument is set to 30
Ensure that the --audit-log-maxbackup argument is set to 10
Ensure that the --audit-log-maxsize argument is set to 100

4.1. Edit the kube-apiserver.yml file under /etc/kubernetes/manifests/ with above details.
root@controlplane /etc/kubernetes/manifests ✖ cd /etc/kubernetes/manifests/

Take a backup of file.
root@controlplane /etc/kubernetes/manifests ✖ cp kube-apiserver.yaml ~/kube-apiserver.yaml
root@controlplane /etc/kubernetes/manifests ✖ vi kube-apiserver.yaml
root@controlplane /etc/kubernetes/manifests ✖ cat kube-apiserver.yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 192.20.3.3:6443
  creationTimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=192.20.3.3
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-admission-plugins=NodeRestriction,PodSecurityPolicy
    - --profiling=false
    - --insecure-port=0
    - --audit-log-path=/var/log/apiserver/audit.log
    - --audit-log-maxage=30
    - --audit-log-maxbackup=10
    - --audit-log-maxsize=100
    - --enable-bootstrap-token-auth=true
    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
    - --etcd-servers=https://127.0.0.1:2379
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
    - --requestheader-allowed-names=front-proxy-client
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
    - --secure-port=6443
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    image: k8s.gcr.io/kube-apiserver:v1.23.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 192.20.3.3
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-apiserver
    readinessProbe:
      failureThreshold: 3
      httpGet:
        host: 192.20.3.3
        path: /readyz
        port: 6443
        scheme: HTTPS
      periodSeconds: 1
      timeoutSeconds: 15
    resources:
      requests:
        cpu: 250m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 192.20.3.3
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: true
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: true
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: true
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: true
    - mountPath: /var/log/apiserver/
      name: audit-log
      readOnly: false
  hostNetwork: true
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      type: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /var/log/apiserver/
      type: DirectoryOrCreate
    name: audit-log
  - hostPath:
      path: /etc/ca-certificates
      type: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /usr/local/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-share-ca-certificates
status: {}

root@controlplane /etc/kubernetes/manifests ➜  

root@controlplane /etc/kubernetes/manifests ➜  kubectl get pod -n kube-system
NAME                                   READY   STATUS    RESTARTS        AGE
coredns-64897985d-94rwd                1/1     Running   0               27m
coredns-64897985d-pd2ss                1/1     Running   0               27m
etcd-controlplane                      1/1     Running   0               27m
kube-controller-manager-controlplane   1/1     Running   1 (3m53s ago)   27m
kube-proxy-pfpqq                       1/1     Running   0               26m
kube-proxy-rzh92                       1/1     Running   0               27m
kube-scheduler-controlplane            1/1     Running   1 (3m53s ago)   27m
weave-net-kk6pg                        2/2     Running   1 (26m ago)     27m
weave-net-vbkpw                        2/2     Running   0               26m

Step 5:
--------
Correct the etcd data directory ownership.

5.1. We can check the steps in /var/www/html/index.html

1.1.12 On the etcd server node, get the etcd data directory, passed as an argument --data-dir,
from the below command:
ps -ef | grep etcd
Run the below command (based on the etcd data directory found above).
For example, chown etcd:etcd /var/lib/etcd

root@controlplane /etc/kubernetes/manifests ➜  chown etcd:etcd /var/lib/etcd

root@controlplane /etc/kubernetes/manifests ➜  

Step 6:
--------
Ensure that the --profiling argument is set to false in kube-controller-manager
6.1. We can find the steps in /var/www/html/index.html
1.3.2 Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml
on the master node and set the below parameter.
--profiling=false

root@controlplane /etc/kubernetes/manifests ➜  vi kube-controller-manager.yaml 
- --profiling=false -- add this line

Step 7:
--------

Ensure that the --profiling argument is set to false in kube-scheduler
7.1. We can find the steps in /var/www/html/index.html
1.4.1 Edit the Scheduler pod specification file /etc/kubernetes/manifests/kube-scheduler.yaml file
on the master node and set the below parameter.
--profiling=false

root@controlplane /etc/kubernetes/manifests ➜  vi kube-scheduler.yaml
- --profiling=false -- add this line